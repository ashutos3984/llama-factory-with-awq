{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you are using GCP then have to run this script."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gv2thzWMR5Qh",
        "outputId": "afe88e0e-1db7-479a-b3c6-22ceb82a67b7"
      },
      "outputs": [],
      "source": [
        "# Clone the AutoAWQ_kernels repository from GitHub\n",
        "# This repository contains the necessary kernels for the AWQ quantization method\n",
        "! git clone https://github.com/casper-hansen/AutoAWQ_kernels.git\n",
        "\n",
        "# Change the current working directory to the cloned AutoAWQ_kernels directory\n",
        "%cd AutoAWQ_kernels\n",
        "\n",
        "# Install the AutoAWQ_kernels package in editable mode\n",
        "# This allows you to make changes to the package and have them reflected immediately without reinstallation\n",
        "! pip install -e .\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you are using Azure then start from here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THJ4fTyZkC-_",
        "outputId": "f38de408-6207-4831-a75c-3e936372dc10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psqEqjuGN_z6",
        "outputId": "0ed86fdc-fa9e-457a-9327-9aa0fcf84e12"
      },
      "outputs": [],
      "source": [
        "# Clone the LLaMA-Factory repository from GitHub\n",
        "# This repository contains the codebase for the LLaMA-Factory, which we will be updating to use the AWQ quantization method\n",
        "!git clone https://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@github.com/ashutos3984/llama-factory-with-awq.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioWx0i-pPLAO",
        "outputId": "76b0338d-9fc6-427b-802e-659b8024968c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/llama-factory-with-awq\n"
          ]
        }
      ],
      "source": [
        "# Change the current working directory to the cloned llama-factory-with-awq directory\n",
        "# This directory contains the codebase for LLaMA-Factory, which will be modified to integrate the AWQ quantization method\n",
        "%cd llama-factory-with-awq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hR8GVBJwPx3D",
        "outputId": "4082f719-454c-4858-99b8-608ab8784367"
      },
      "outputs": [],
      "source": [
        "# Install the required Python packages listed in the requirements.txt file\n",
        "# This ensures that all dependencies needed for running LLaMA-Factory are installed\n",
        "! pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhpBg_KPQeAG",
        "outputId": "54068fd1-bf91-4231-d54c-774692191875"
      },
      "outputs": [],
      "source": [
        "# Install the LLaMA-Factory package in editable mode along with additional optional dependencies\n",
        "# The optional dependencies are specified in brackets and include:\n",
        "# - metrics: Additional metrics for evaluation\n",
        "# - bitsandbytes: Efficient computation library for large models\n",
        "# - qwen: Additional quantization methods\n",
        "# - awq: AWQ quantization method\n",
        "! pip install -e .[metrics,bitsandbytes,qwen,awq]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtNgYfRSkdu-",
        "outputId": "11b03de3-667a-40b4-ca6e-c6e49a41ecf8"
      },
      "outputs": [],
      "source": [
        "# Install the huggingface_hub package\n",
        "# This package provides utilities to interact with the Hugging Face Hub, which hosts models, datasets, and other resources for NLP tasks\n",
        "! pip install huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvkECT03ksLg",
        "outputId": "2ca55c21-c52e-424a-db39-9e2b27e815b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) y\n",
            "Token is valid (permission: write).\n",
            "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "# Log in to the Hugging Face Hub using the Hugging Face CLI\n",
        "# This command will prompt you to enter your Hugging Face credentials (username and password)\n",
        "# Logging in allows you to push and pull models, datasets, and other resources from your Hugging Face account\n",
        "! huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "N5nNuSS7SMpu",
        "outputId": "58a5a7fc-9032-4aab-eaf8-edbcc42085b5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/llama-factory-with-awq'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0G_jWfmRkyVf",
        "outputId": "a5350766-56d9-4dac-d35e-cb4304709c51"
      },
      "outputs": [],
      "source": [
        "# Run the web UI for LLaMA-Factory\n",
        "# This script starts the web user interface for LLaMA-Factory, allowing you to interact with the application via a browser\n",
        "! python src/webui.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rkojtd3DmJWq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
